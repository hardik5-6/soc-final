{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RksWtNuHg9Rb"
   },
   "source": [
    "# CNN-lytical Assignment-1\n",
    "*  In this assignment, we will build a classifier for MNIST from scratch using just [NumPy](https://numpy.org/)\n",
    "\n",
    "*  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of handwritten digits of size 28x28\n",
    "\n",
    "*  The dataset that you are expected to use for training can be found [here](https://drive.google.com/file/d/1z7lwIml6UxsNpDIW3_mPPEb8SoaPC5Zg/view)\n",
    "\n",
    "*   Our model will have 1 hidden layer, like the one below (not our recommendation to use 256 in the hidden layer though, try various values out)\n",
    "\n",
    "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**\n",
    "\n",
    "<center>\n",
    "<img src=\"https://user-images.githubusercontent.com/81357954/166119893-4ca347b8-b1a4-40b8-9e0a-2e92b5f164ae.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyOAG55siwdI"
   },
   "source": [
    "## Import libraries here\n",
    "NumPy, Matplotlib, ...\n",
    "\n",
    "Also remember to initialize the seed for reproducibility of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7iVUsRLxjAb9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaLDC4wN0eQs"
   },
   "source": [
    "## Load *Dataset*\n",
    "Load data from the given pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6qOjNSmx0iUn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 968 1104 1022  989 1011  919  994 1046  992  955]\n"
     ]
    }
   ],
   "source": [
    "# mount Google Drive to access the dataset\n",
    "import pickle\n",
    "# load the data set\n",
    "pklData = pickle.load(open('./train_data.pkl', 'rb'))\n",
    "def normalize(X:np.ndarray):\n",
    "    # print(X.shape)\n",
    "    mean = np.average(X,axis=1).reshape(X.shape[0],1)\n",
    "    # print(mean.shape)\n",
    "    X = X-mean\n",
    "    std=np.std(X,axis=1).reshape(X.shape[0],1)\n",
    "    # print(std.shape)\n",
    "    X = X/std\n",
    "    # print(X[0])\n",
    "    return X\n",
    "def standardize(X:np.ndarray):\n",
    "    minvals = np.min(X,axis=1).reshape(X.shape[0],1)\n",
    "    maxvals = np.max(X,axis=1).reshape(X.shape[0],1)\n",
    "    X = (X-minvals)/(0.0001+maxvals-minvals)\n",
    "    return X\n",
    "X = np.array(pklData['X'])\n",
    "y = np.array(pklData['y'])\n",
    "X = normalize(X)\n",
    "\n",
    "# TODO:update training set, testing set size so total = 60k\n",
    "k = 100\n",
    "X_train = X[:10000]\n",
    "Y_train = y[:10000]\n",
    "\n",
    "# print(Y_train.shape)\n",
    "print(np.unique(Y_train,return_counts=True)[1])\n",
    "X_test = X[k:2*k]\n",
    "Y_test = y[k:2*k]\n",
    "hidLaySize = 256\n",
    "numDigs = 10\n",
    "# Split into X_train, y_train, X_test, y_test\n",
    "# you can use stratified splitting from sklearn library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "id77Oqc90kTf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HARDIK RAJPAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\text.py:1223: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a 4x4 grid, \n",
    "# choose 16 images randomly, display the images as well as corresponding labels\n",
    "selection = np.random.choice(np.arange(X_train.shape[0]),size=16)\n",
    "selImages = X_train[selection]\n",
    "selLabels = Y_train[selection]\n",
    "fig,axs = plt.subplots(4,4)\n",
    "fig.tight_layout()\n",
    "from typing import List\n",
    "# axs:List[plt.Axes]\n",
    "# axs[0].imshow()\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i,j].set_xticks([])\n",
    "        axs[i,j].set_yticks([])\n",
    "        axs[i,j].imshow(selImages[4*i+j].reshape(28,28),cmap='gray',vmin=-1,vmax=1)\n",
    "        axs[i,j].set_title(selLabels[4*i+j])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFYnsPVLmsiW"
   },
   "source": [
    "## Building up parts of our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAsGtgxUpGh2"
   },
   "source": [
    "**Activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6Di5Ck47msCQ"
   },
   "outputs": [],
   "source": [
    "def relu(z:np.ndarray):\n",
    "    negz = z < 0;ans = z.copy()\n",
    "    ans[negz] = 0\n",
    "    return ans\n",
    "def sigmoid(z:np.ndarray):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "def sigmoid_derivative(z:np.ndarray):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "def softmax(z:np.ndarray):\n",
    "    b = np.exp(z)\n",
    "    b = b/np.sum(b)\n",
    "    # np.apply_along_axis(lambda y: print(np.sum(y)),1,b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-q5HJHIocdn"
   },
   "source": [
    "**Notes about the Neural Network** \n",
    "*   Input size is (784,) because 28x28 = 784\n",
    "*   Output size will be 10, each element represeting probability of the image representing that digit\n",
    "*   Size of the hidden layer is a hyperparameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azTAuS5spFcz"
   },
   "source": [
    "**Initialize the layers weights**\n",
    "\n",
    "Generally, we follow the convention that weights are drawn from a standard normal distribution, while the bias vectors are initialized to zero. But you can try everything out :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "38E3_hVPocMm"
   },
   "outputs": [],
   "source": [
    "def init_params(sizeList):\n",
    "    return [np.random.normal(0,1,size=size) for size in sizeList]\n",
    "def init_bias(sizeList):\n",
    "    # return [np.random.normal(0,1,size=size) for size in sizeList]\n",
    "    return [np.zeros(size) for size in sizeList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlX8zy-7pv2n"
   },
   "source": [
    "**Forward Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TJ8lgrqjjASz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def forward_propg(X:np.ndarray, weights:List[np.ndarray],biases:List[np.ndarray]):\n",
    "    \"X is a list of images of size 784\"\n",
    "    \"X.shape = (N,784)\"\n",
    "    \"weights[0].shape = (hls,784)\"\n",
    "    \"biases[0].shape = (hls)\"\n",
    "    \"z1.shape = (N,hls)\"\n",
    "    \"weights[1].shape = (10, hls)\"\n",
    "    \"biases[1].shape = (10)\"\n",
    "    hls = weights[0].shape[0]\n",
    "    actFunc = relu\n",
    "    actFunc2 = sigmoid\n",
    "    z1 = np.matmul(X,weights[0].transpose())\n",
    "    z1 = z1 + biases[0]\n",
    "    \"z1.shape = (N,hls)\"\n",
    "    #doubt: batch normalization?\n",
    "    a1 = actFunc(z1)\n",
    "    a1 = standardize(a1)\n",
    "    #N,hls = (N,784)x(hls,784)\n",
    "    z2 = np.matmul(a1, weights[1].transpose())\n",
    "    z2 = z2+ biases[1]\n",
    "    a2 = actFunc(z2)\n",
    "    a2 = standardize(a2)\n",
    "    probs = standardize(np.apply_along_axis(\n",
    "        lambda y:(y+1)/np.sum(y+1),\n",
    "        1,\n",
    "        a2\n",
    "    ))\n",
    "    \"a2.shape = (N,10)\"\n",
    "    # print(1.000001-a2)\n",
    "    logits = np.vectorize(lambda x:np.log(abs(x/(1.001-x))))(a2)\n",
    "    \"\"\"\n",
    "    X: input data\n",
    "    returns: logits, output of each layer z1,z2,\n",
    "    activation of each layer: a1,a2\n",
    "    \"\"\"\n",
    "    return logits,z1,z2,a1,a2,probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asZmbRVvuy5x"
   },
   "source": [
    "**Backward Propagation**\n",
    "\n",
    "\n",
    "You may use stochastic gradient descent or batch gradient descent here. Feel free to use any loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kAmrTAlimjUN"
   },
   "outputs": [],
   "source": [
    "def backward_propg(weights, biases,X, yscores, outputs,lr):\n",
    "    \"X.shape = (N,784)\"\n",
    "    \"yscores.shape = (N,10): true labels\"\n",
    "    \"outputs = [z1,a1,z2,a2]:\"\n",
    "    \"z2.shape = (N,10)\"\n",
    "    \"z1.shape = (N,hls)\"\n",
    "    \"biases[0] = (hls)\"\n",
    "    \"biases[1] = (10)\"\n",
    "    \"weights[0] = (hls,784)\"\n",
    "    \"weights[1] = (10,hls)\"\n",
    "    N = X.shape[0];z1,a1,z2,a2 = outputs;hls = weights[0].shape[0]\n",
    "    # a2diffy = (a2-yscores)*sigmoid_derivative(z2)\n",
    "    a2diffy = (a2-yscores)\n",
    "\n",
    "    #               10xN,Nxh\n",
    "    dwo = (2/N)*np.matmul(a2diffy.transpose(),a1)\n",
    "    weights[1]-=lr*dwo\n",
    "    biases[1]-=np.average(a2diffy,axis=0)\n",
    "    dEseps = (2/10)*np.matmul(a2diffy,weights[1])\n",
    "    #Nx10  10xh\n",
    "    #Nxh\n",
    "                    # hx784 = hxN x Nx784\n",
    "    dwh = np.matmul(dEseps.transpose(),X)/X.shape[0]\n",
    "    weights[0]-=lr*(dwh)\n",
    "    biases[0]-=lr*(np.average(dEseps,axis=0))\n",
    "    return weights,biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cVDz0IGnvzpe"
   },
   "outputs": [],
   "source": [
    "def cost_func(scores:np.ndarray,y:np.ndarray,params):\n",
    "    \"scores: (N,10)\"\n",
    "    \"y: (N,10)\"\n",
    "    N = scores.shape[0]\n",
    "    # print(scores.shape,y.shape)\n",
    "    #correct the loss function\n",
    "    diff = (scores-y)**2\n",
    "    losses = np.apply_along_axis(\n",
    "        lambda x:np.sum(diff[x],axis=1),\n",
    "        0,\n",
    "        np.arange(N)\n",
    "    )\n",
    "    \"losses.shape = (N,1)\"\n",
    "    # print(f\"losses shape:{losses.shape}\")\n",
    "    dataLoss = np.average(losses)\n",
    "    \"\"\"\n",
    "    calculate loss to check whether it is decreasing at each epoch or not\n",
    "    one can return this in backward propagation as well\n",
    "    \"\"\"\n",
    "    return dataLoss,losses\n",
    "def accuracy(predictions, y:np.ndarray):\n",
    "    y=y.flatten()\n",
    "    # print(predictions.shape,y.shape)\n",
    "    # print(np.where(predictions==y)[0])\n",
    "    # print(np.where(predictions==y)[0].shape,y.shape[0])\n",
    "    return np.round(100*np.where(predictions==y)[0].shape[0]/y.shape[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUlhpcs9ylOX"
   },
   "source": [
    "\n",
    "## Integrate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SDGdT7PVmjRU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARDIK RAJPAL\\AppData\\Local\\Temp\\ipykernel_3916\\3607970557.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "  logits = np.vectorize(lambda x:np.log(abs(x/(1.001-x))))(a2)\n",
      "c:\\Users\\HARDIK RAJPAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:2387: RuntimeWarning: divide by zero encountered in <lambda> (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr:0, cost:0.4793028941960385,accur:60.94\n",
      "itr:1, cost:0.3772659516298846,accur:76.65\n",
      "itr:2, cost:0.35626433292466797,accur:79.41\n",
      "itr:3, cost:0.333312697802578,accur:80.83\n",
      "itr:4, cost:0.316187563445906,accur:81.69\n",
      "itr:5, cost:0.3128906317281564,accur:82.47\n",
      "itr:6, cost:0.2967373898067703,accur:83.1\n",
      "itr:7, cost:0.28990477040001844,accur:83.36\n",
      "itr:8, cost:0.27934931340859653,accur:83.79\n",
      "itr:9, cost:0.27441369684158234,accur:84.07\n",
      "itr:10, cost:0.260652811219795,accur:84.43\n",
      "itr:11, cost:0.2468432947737871,accur:84.85\n",
      "itr:12, cost:0.26288187986296313,accur:85.04\n",
      "itr:13, cost:0.27353989502765735,accur:85.19\n",
      "itr:14, cost:0.2381244334327599,accur:85.44\n",
      "itr:15, cost:0.23531765075844815,accur:85.81\n",
      "itr:16, cost:0.24382556746436634,accur:85.94\n",
      "itr:17, cost:0.2218556304200963,accur:86.14\n",
      "itr:18, cost:0.2180420350017092,accur:86.44\n",
      "itr:19, cost:0.22691661131034102,accur:86.59\n",
      "itr:20, cost:0.23250978612119103,accur:86.66\n",
      "itr:21, cost:0.23613750413422113,accur:86.86\n",
      "itr:22, cost:0.24473700968361098,accur:87.15\n",
      "itr:23, cost:0.21271476831735295,accur:87.32\n",
      "itr:24, cost:0.2242901521089381,accur:87.42\n",
      "itr:25, cost:0.2061436898611339,accur:87.52\n",
      "itr:26, cost:0.19265716322764892,accur:87.63\n",
      "itr:27, cost:0.18279427740715498,accur:87.85\n",
      "itr:28, cost:0.18608848578959875,accur:88.19\n",
      "itr:29, cost:0.1824322679527712,accur:88.27\n",
      "itr:30, cost:0.2049274723935534,accur:88.13\n",
      "itr:31, cost:0.19305469834778127,accur:88.27\n",
      "itr:32, cost:0.17893450875036895,accur:88.48\n",
      "itr:33, cost:0.19292937963459322,accur:88.45\n",
      "itr:34, cost:0.20336261719357324,accur:88.59\n",
      "itr:35, cost:0.19576992188108314,accur:88.65\n",
      "itr:36, cost:0.18981714265836871,accur:88.83\n",
      "itr:37, cost:0.18841730069858414,accur:88.89\n",
      "itr:38, cost:0.19681198471582684,accur:88.97\n",
      "itr:39, cost:0.18397602148295988,accur:89.1\n",
      "itr:40, cost:0.19880653959365824,accur:89.08\n",
      "itr:41, cost:0.19457739704583538,accur:89.34\n",
      "itr:42, cost:0.21021902726328548,accur:89.27\n",
      "itr:43, cost:0.19040584382721287,accur:89.32\n",
      "itr:44, cost:0.17663257453767092,accur:89.47\n",
      "itr:45, cost:0.19541536056431932,accur:89.45\n",
      "itr:46, cost:0.18076430670663604,accur:89.7\n",
      "itr:47, cost:0.20231778474347625,accur:89.67\n",
      "itr:48, cost:0.189976190893995,accur:89.72\n",
      "itr:49, cost:0.19623236255218923,accur:89.91\n",
      "hls: 256; maxacc:89.91\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "def train(X, y, hidden_nodes, epochs=1000, lr=1e-5):\n",
    "    \"\"\"\n",
    "    hidden_nodes: no. of nodes in hidden layer\n",
    "\n",
    "    should return the updated optimize weights.\n",
    "    \"\"\"\n",
    "\n",
    "    weights = init_params([(hidden_nodes,784),(numDigs,hidden_nodes)])\n",
    "    biases = init_bias([hidden_nodes,numDigs])\n",
    "    valToScores = lambda val:np.vectorize(lambda x: 1 if x==val else 0)\n",
    "    aranged = np.arange(10)#[1,2,...,10]\n",
    "    scoreArray  =np.apply_along_axis(\n",
    "        lambda y_elem:valToScores(y_elem)(aranged),\n",
    "        1,\n",
    "        y\n",
    "    )\n",
    "    # print(scoreArray[:10])\n",
    "    numbatches = 100\n",
    "    mbs = int(X.shape[0]/numbatches)\n",
    "    pltable=np.zeros((2,epochs))\n",
    "    # print(f'mbs:{mbs}')\n",
    "    #mini batch size\n",
    "    for i in range(epochs):\n",
    "        accs = []\n",
    "        for j in range(numbatches):\n",
    "            logits,z1,z2,a1,a2,probs = forward_propg(X[mbs*j:mbs*(j+1)],weights,biases)\n",
    "            cost,losses = cost_func(probs,scoreArray[mbs*j:mbs*(j+1)],[])\n",
    "            preds = np.apply_along_axis(\n",
    "                lambda x:np.argsort(x)[-1],\n",
    "                1,\n",
    "                probs)\n",
    "            # print(probs[:10])\n",
    "            acc = accuracy(preds,y[mbs*j:mbs*(j+1)].reshape(mbs))\n",
    "            accs.append(acc)\n",
    "            newweights, newbiases = backward_propg(weights,biases,X[mbs*j:mbs*(j+1)],scoreArray[mbs*j:mbs*(j+1)],[z1,a1,z2,a2],lr)\n",
    "            weights = newweights\n",
    "            biases = newbiases\n",
    "        pltable[0,i] = cost;pltable[1,i]=np.average(accs)\n",
    "        # if(i%5==0):\n",
    "        #     clear_output(wait=True)\n",
    "        #     # plt.plot(np.arange(epochs)[:i+1],pltable[0,:i+1],pltable[1,:i+1])\n",
    "        #     plt.plot(np.arange(epochs)[:i+1],pltable[0,:i+1])\n",
    "        #     plt.show()\n",
    "        print(f'itr:{i}, cost:{pltable[0,i]},accur:{pltable[1,i]}')\n",
    "            # print(i,)\n",
    "            # print cost at every 100 or so iterations\n",
    "        # backward propagation\n",
    "    print(f'hls: {hidden_nodes}; maxacc:{np.max(pltable[1,:])}')\n",
    "    return weights,biases,np.max(pltable[1,:])\n",
    "# maxaccs = []\n",
    "# for hlstmp in range(10,hidLaySize,5):\n",
    "    # maxaccs.append(train(X_train,Y_train,hidden_nodes=hlstmp,epochs=100)[1])\n",
    "w,b,max = train(X_train,Y_train,hidden_nodes=hidLaySize,epochs=50,lr=1e-1)\n",
    "\n",
    "# print(maxaccs)\n",
    "# print(np.unique(Y_train,return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 15.0), (15, 15.0), (20, 13.0), (25, 12.0), (30, 12.0), (35, 7.0), (40, 13.0), (45, 19.0), (50, 12.0), (55, 13.0), (60, 10.0), (65, 6.0), (70, 17.0), (75, 12.0), (80, 15.0), (85, 12.0), (90, 13.0), (95, 11.0), (100, 18.0), (105, 12.0), (110, 10.0), (115, 4.0), (120, 10.0), (125, 14.0), (130, 16.0), (135, 11.0), (140, 10.0), (145, 13.0), (150, 13.0), (155, 9.0), (160, 12.0), (165, 8.0), (170, 11.0), (175, 13.0), (180, 8.0), (185, 13.0), (190, 22.0), (195, 15.0), (200, 13.0), (205, 14.0), (210, 14.0), (215, 11.0), (220, 17.0), (225, 15.0), (230, 9.0), (235, 10.0), (240, 11.0), (245, 9.0), (250, 11.0), (255, 22.0)]\n"
     ]
    }
   ],
   "source": [
    "# print((list(map(lambda z:(z[0]*5+10,z[1]),list(enumerate(maxaccs))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "9XBinWpPmjOS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARDIK RAJPAL\\AppData\\Local\\Temp\\ipykernel_46304\\3416355029.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  logits = np.vectorize(lambda x:np.log(abs(x/(1.001-x))))(a2)\n"
     ]
    }
   ],
   "source": [
    "tn = 1000\n",
    "def predict(X, updated_weights,biases):\n",
    "    _,_,_,_,_,probs=forward_propg(X,updated_weights,biases)\n",
    "    # print(probs.shape)\n",
    "    # np.savetxt('preds.csv',probs)\n",
    "    # np.savetxt('ans.csv',Y_test[:tn])\n",
    "    # for i in range(tn):\n",
    "    #     plt.scatter(np.arange(1,11),probs[i,:])\n",
    "    #     plt.xticks(np.arange(1,11))\n",
    "    #     plt.show()\n",
    "        # print(probs[i,:])\n",
    "        # print(np.argsort(probs[i,:]))\n",
    "    # print()\n",
    "    \n",
    "    return np.apply_along_axis(lambda x: np.argsort(x)[-1],1,probs)\n",
    "preds = predict(X_test[:tn],w,b)\n",
    "# print(preds.shape)\n",
    "print(accuracy(preds,Y_test[:tn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGVOZ8yg0VrV"
   },
   "source": [
    "### Save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARDIK RAJPAL\\AppData\\Local\\Temp\\ipykernel_46304\\3416355029.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  logits = np.vectorize(lambda x:np.log(abs(x/(1.001-x))))(a2)\n"
     ]
    }
   ],
   "source": [
    "pklData2 = pickle.load(open('./model_200050048.pkl', 'rb'))\n",
    "hd = pklData2['z']\n",
    "w2 = [np.array(pklData2['layer_0_wt']).transpose(),np.array(pklData2['layer_1_wt']).transpose()]\n",
    "b2 = [np.array(pklData2['layer_0_bias']).flatten(),np.array(pklData2['layer_1_bias']).flatten()]\n",
    "preds = predict(X_test[:tn],w2,b2)\n",
    "print(accuracy(preds,Y_test[:tn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "_lvDVwmxmjKX",
    "outputId": "02467c3f-b20f-44b7-8e3d-43e308028d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 784)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "# from google.colab import files\n",
    "\n",
    "roll_num = \"200050048\" # enter ldap\n",
    "hidden_dim = hidLaySize # replace with your own hidden dimension\n",
    "\n",
    "model_dict = {\n",
    "    'z': hidden_dim, # hidden dimension of your model\n",
    "    'layer_0_wt': w[0].transpose(), # layer 0 weight (784, z)\n",
    "    'layer_0_bias': b[0].reshape((hidden_dim,1)), # layer 0 bias (z, 1)\n",
    "    'layer_1_wt': w[1].transpose(), # layer 1 weight (z, 10)\n",
    "    'layer_1_bias': b[1].reshape((10,1)) # layer 1 bias (10, 1)\n",
    "}\n",
    "print(w[0].shape)\n",
    "assert model_dict['layer_0_wt'].shape == (784, hidden_dim)\n",
    "assert model_dict['layer_0_bias'].shape == (hidden_dim, 1)\n",
    "assert model_dict['layer_1_wt'].shape == (hidden_dim, 10)\n",
    "assert model_dict['layer_1_bias'].shape == (10, 1)\n",
    "\n",
    "with open(f'model_{roll_num}.pkl', 'wb') as f:\n",
    "    pickle.dump(model_dict, f)\n",
    "    # files.download(f'model_{roll_num}.pkl') # download the file from the Colab session for submission"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-lytical Assignment-1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "298688196bc8e687415b66e58936d8aa4a9e739c7b4683a3c0ec1143ce8e53ab"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
