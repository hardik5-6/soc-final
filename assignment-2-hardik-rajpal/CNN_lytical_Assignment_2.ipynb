{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwo8D8V-uPsI"
      },
      "source": [
        "# CNN-lytical Assignment-2\n",
        "<center>\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS7fZ0PJ4leQi4qtXR5Egv5YILqQqvzVSNtFg&usqp=CAU\">\n",
        "</center>\n",
        "\n",
        "*  In this assignment, we will build a classifier for MNIST from using [PyTorch](https://pytorch.org/docs/stable/index.html). \n",
        "\n",
        "*   We will be using the same dataset as the previous assignment for MNIST. **Do not** use the complete MNIST dataset, even though PyTorch makes it really easy.\n",
        "\n",
        "*   No limitations on your model this time, just don't use CNNs now, that's up next week.\n",
        "\n",
        "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQNvtQCE_j1Q"
      },
      "source": [
        "## Import libraries here\n",
        "PyTorch, NumPy, Matplotlib, ...\n",
        "Even when equipped with PyTorch, NumPy and Matplotlib make your work easier for visualization etc.\n",
        "\n",
        "Also remember to **initialize the seed** for reproducibility of results, both for NumPy & PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CnnyxVTxqpZB"
      },
      "outputs": [],
      "source": [
        "import torch as pt\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "np.random.seed(0) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6dAe4V0_3zC"
      },
      "source": [
        "## Load *Dataset*\n",
        "Use the pickle file shared for the previous assignment here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 784]) torch.Size([60000, 10])\n"
          ]
        }
      ],
      "source": [
        "data = pkl.load(open('train_data.pkl','rb'))\n",
        "# print(data.keys())\n",
        "X = pt.tensor(data['X']).float()\n",
        "y = pt.tensor(data['y']).float()\n",
        "valToScores = lambda val:np.vectorize(lambda x: 1 if x==val else 0)\n",
        "aranged = np.arange(10)#[1,2,...,10]\n",
        "scoreArray  =np.apply_along_axis(\n",
        "    lambda y_elem:valToScores(y_elem)(aranged),\n",
        "    1,\n",
        "    y\n",
        ")\n",
        "y=pt.from_numpy(scoreArray).float()\n",
        "print(X.shape,y.shape)\n",
        "k = 1024*32\n",
        "X_train = X[:k]\n",
        "Y_train = y[:k]\n",
        "X_test = X[k:2*k]\n",
        "Y_test = y[k:2*k]\n",
        "hls = 256\n",
        "imgdim = 784\n",
        "numdigs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w4174DiUAUIJ"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "selection = np.random.choice(np.arange(X_train.shape[0]),size=16)\n",
        "selImages = X_train[selection].numpy()\n",
        "selLabels = Y_train[selection].numpy()\n",
        "fig,axs = plt.subplots(4,4)\n",
        "fig.tight_layout()\n",
        "from typing import List\n",
        "# axs:List[plt.Axes]\n",
        "# axs[0].imshow()\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        axs[i,j].set_xticks([])\n",
        "        axs[i,j].set_yticks([])\n",
        "        axs[i,j].imshow(selImages[4*i+j].reshape(28,28),cmap='gray',vmin=-1,vmax=1)\n",
        "        axs[i,j].set_title(selLabels[4*i+j].argsort()[-1],color='blue')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjY5oNGRAK1e"
      },
      "source": [
        "## Creating a Dataset Class\n",
        "In PyTorch, there is existing implementation of batch-splitting. You don't need to do it manually over here. Instead, just define a Dataset class and a Dataloader wrapping it.\n",
        "\n",
        "A dataset class must have 3 functions - ```__init__```, ```__len__```, ```__getitem__```. Their names are pretty self-explanatory. You can read more about this [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n",
        "\n",
        "\n",
        "**Note** - Things like normalization, augmentation etc. which are related to the dataset are all done in this class. However, because this assignment doesn't deal with MNIST images but rather feature vectors, this part is being skipped here and will be discussed in Assignment 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vifSrimqBGjH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([27232, 10])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define your dataset class\n",
        "class Dataset:\n",
        "    def __init__(self,X,Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "    def __getitem__(self, i):\n",
        "        if(i<len(self.Y)):\n",
        "            return self.X[i],self.Y[i]\n",
        "train_data = Dataset(X_train,Y_train)\n",
        "test_data = Dataset(X_test,Y_test)\n",
        "print(Y_test.shape)\n",
        "trainDataLoader = DataLoader(train_data,batch_size=64,shuffle=True)\n",
        "testDataLoader = DataLoader(test_data,batch_size=50,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOs6uifpBF8P"
      },
      "source": [
        "## ```nn.Module``` for your model\n",
        "In this segment, define a class for your model, it has to inherit from the ```nn.Module``` class. You must define two functions here - ```__init__``` and ```forward```, again pretty self-explanatory. Helper functions can also be implemented, your choice!\n",
        "\n",
        "Look into the following ```torch``` layers and combine them to form your network, you can find more [here](https://pytorch.org/docs/stable/nn.html) -\n",
        "- [```nn.Linear```](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "- [```nn.ReLU```](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "- [```nn.BatchNorm1d```](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Mr6_5pzGRjp"
      },
      "outputs": [],
      "source": [
        "class MaNet(pt.nn.Module):\n",
        "    def __init__(self,imgdims,hdls,nmdigs):\n",
        "        super(MaNet,self).__init__()\n",
        "        self.linear1 = pt.nn.Linear(imgdims,hdls,bias=True)\n",
        "        self.relu1 = pt.nn.ReLU()\n",
        "        self.normalize1 = pt.nn.BatchNorm1d(hdls)\n",
        "        self.linear2 = pt.nn.Linear(hdls,nmdigs,bias=True)\n",
        "        self.relu2 = pt.nn.ReLU()\n",
        "        self.normalize2 = pt.nn.BatchNorm1d(nmdigs)\n",
        "    def forward(self,x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.normalize1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.normalize2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVTyirdELXlt"
      },
      "source": [
        "## Training loop\n",
        "You can write a training loop but usually writing it within a function helps so that you can train in multiple passes with just one function call if you still don't see convergence of the loss. ```display_step``` is for you to display results on the validation set (which you must not have trained upon).\n",
        "\n",
        "You will need to use ```zero_grad()```, ```backward()``` and multiple such functions here. Look for them in the tutorials given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z0BnrNm8LN5s"
      },
      "outputs": [],
      "source": [
        "def train(model:MaNet, optimizer:pt.optim.SGD, criterion, train_loader:DataLoader,epochs=100, display_step=None):\n",
        "    for i in range(epochs):\n",
        "        lossData = []\n",
        "        for j,data in enumerate(train_loader,0):\n",
        "            indata,target = data\n",
        "            # print(indata,type(indata))\n",
        "            optimizer.zero_grad()\n",
        "            output = model(indata)\n",
        "            loss = criterion(output,target)\n",
        "            lossData.append(loss.item())\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(np.average(lossData))\n",
        "    return lossData,model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g319ipPXMh0R"
      },
      "source": [
        "## Initialize weights\n",
        "Write a small function to initialize weights for your model. You don't need to do it individually for each layer, there are ways to do it in a simple ```for``` loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GRqqKNLZMjDe"
      },
      "outputs": [],
      "source": [
        "def init_weights():\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivuHRGtfN3sE"
      },
      "source": [
        "## Prediction & Accuracy\n",
        "Prediction function should predict outputs using your trained model for a given **NumPy array** ```X_test``` and the output should be another **NumPy array**.\n",
        "\n",
        "The accuracy function would be the same as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cPX1q_0AN3ZV"
      },
      "outputs": [],
      "source": [
        "def predict(model, X_test):\n",
        "    output = model(X_test)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_nKROVpWOa6j"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred, labels):\n",
        "    labelsFlat = labels.numpy().argsort(axis=1)[:,-1].transpose()\n",
        "    return np.round(100*np.where(\n",
        "            labelsFlat\n",
        "            ==\n",
        "            pred.detach().numpy().argsort(axis=1)[:,-1]\n",
        "            )[0].shape[0]/labelsFlat.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aA1EWZmMbQe"
      },
      "source": [
        "## Actually training your model\n",
        "- Create a model, initialize it. Define optimizer for the model as well as loss criterion (you can actually set the seed here again, just in case you did some ```rand``` calls above for testing your functions).\n",
        "- Define an instance of the dataset class, wrap it in a dataloader.\n",
        "- Call the train function and train your model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F8JG_XURNLmr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.29918045028171036\n",
            "0.05449119066543062\n",
            "0.027351877261025948\n",
            "0.023271281042980263\n"
          ]
        }
      ],
      "source": [
        "model = MaNet(imgdim,hls,numdigs)\n",
        "optimizer = pt.optim.SGD(model.parameters(),lr=0.01)\n",
        "criterion = pt.nn.MSELoss()\n",
        "lossdata, newModel= train(model,optimizer,criterion,trainDataLoader,epochs=2)\n",
        "# lossdata, newModel= train(newModel,optimizer,criterion,trainDataLoader,epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQsiK0-COe6E"
      },
      "source": [
        "## Run your model for the validation dataset\n",
        "Use your trained model to get predictions for the validation dataset you split earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i_B_NUjUOq3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50, 10]) <class 'torch.Tensor'>\n",
            "Loss on 0 test Data:0.028005382046103477; Acc:86.0\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for j,data in enumerate(testDataLoader):\n",
        "        testd,testlabs= data\n",
        "        print(testlabs.size(),type(testlabs))\n",
        "        output = predict(newModel,testd)\n",
        "        loss = pt.nn.MSELoss()(output,testlabs)\n",
        "        acc = accuracy(output,testlabs)\n",
        "        print(f\"Loss on {j} test Data:{loss.item()}; Acc:{acc}\")\n",
        "        i+=1\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f4W_facj-PA"
      },
      "source": [
        "## Submission\n",
        "To submit your solution, you will need to make a file with name ```model.py``` containing imports necessary to write the model class and the model class itself. It shouldn't do anything else when run. Other than this, save the trained model in a file named ```ass_2.pt```. When you are done with the assignment, commit the updated notebook, the ```model.py``` class file and the ```ass_2.pt``` model-weights file to the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "7tknYAy1j92M"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "pt.save(newModel, 'ass_2.pt')\n",
        "# files.download('ass_2.pt') # download the file from the Colab session for submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flMRBW9Akhkg"
      },
      "source": [
        "Check if it got saved right!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-wA9nHzYkj1R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98.0\n"
          ]
        }
      ],
      "source": [
        "# load the model, use predict function\n",
        "model = pt.load('ass_2.pt')\n",
        "for data in testDataLoader:\n",
        "    testB1,testL1 = data\n",
        "    output = predict(newModel,testB1)\n",
        "    acc = accuracy(output,testL1)\n",
        "    print(acc)\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN-lytical Assignment-2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "298688196bc8e687415b66e58936d8aa4a9e739c7b4683a3c0ec1143ce8e53ab"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
